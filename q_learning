"""
  Use CliffWalking to demonstrate the usage and algorithm of q_learning

  * Update Gym, code needs to update
"""

import gym
import numpy as np
import gridworld

class QLearningAgent(object):
    def __init__(self, n_status, n_act, lr=0.1, gamma=0.9, e_greed=0.1):
        self.n_status = n_status
        self.n_act = n_act 
        self.lr = lr 
        self.gamma = gamma 
        self.epsilon = e_greed
        self.Q = np.zeros((n_status, n_act))

    def predict(self, state):
        #return np.argmax(self.Q[state, :]) 
        Q_list = self.Q[state, :]
        action = np.random.choice(np.flatnonzero(Q_list == Q_list.max()))
        return action

    def act(self, state):
        if np.random.uniform(0, 1) < self.epsilon:
            action = np.random.choice(self.n_act)
        else:
            action = self.predict(state)
        return action

    def learn(self, state, action, reward, next_state, done):
        predict_Q = self.Q[state, action]
        target_Q = reward + (1 - float(done)) * self.gamma * self.Q[next_state, :].max()
        self.Q[state, action] += self.lr * (target_Q - predict_Q) 


def train_episode(env, agent,is_render):
    total_reward = 0
    state = env.reset()

    while True:
        action = agent.act(state) 
        next_state, reward, done, info = env.step(action)

        agent.learn(state, action, reward, next_state, done)

        state = next_state

        total_reward += reward

        if is_render: env.render()
        if done: break

    return total_reward


def test_episode(env, agent):
    total_reward = 0
    state = env.reset()

    while True:
        action = agent.predict(state)
        next_state, reward, done, _ = env.step(action)
        total_reward += reward
        state = next_state
        env.render()

        if done:break

    return total_reward

def train(env,episodes=500,lr=0.1,gamma=0.9,e_greed=0.1):
    agent = QLearningAgent(
        n_status=env.observation_space.n,
        n_act=env.action_space.n,
        lr=lr,
        gamma=gamma,
        e_greed=e_greed)

    is_render = False
    for e in range(episodes):
        ep_reward = train_episode(env, agent,is_render)
        print('Episode %s: reward = %.1f' % (e, ep_reward))
        if e % 50 == 0:
            is_render = True
        else:
            is_render = False

    test_reward = test_episode(env, agent)
    print('test reward = %.1f' % (test_reward))


if __name__ == '__main__':
    env = gym.make("CliffWalking-v0")
    env = gridworld.CliffWalkingWapper(env)
    train(env)
